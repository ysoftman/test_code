# DeepLearning 요약 정리
## 개발 환경
- python 3.x
- numpy : 각종 수식을 쉽게 처리할 수 있는 다양한 기능 제공
- matplotlib : 데이터를 그래프로 표시

## 퍼셉트론(Perceptron)
- 다수의 신호를 입력으로 받아 하나의 신호촐 출력하는 모델
  - DeepLearning(예전에는 NeuralNet이라고 불림) 의 기원이됨
- x1, x2 node(뉴런) 에서 각가 w1, w2 가중치가 곱해져 y 출력되는 형태
- 쉽게 활성화(출력이 1이되는)하기 위해 bias(편향) 을 추가
- 각 노드에는 가중치와 편향이라는 파라미터가 존재
- 한개의 단편적인 퍼셉트론은 선형 문제만 처리(인식,분류...등)하고 비선형 문제는 처리할 수 없어 여러 개의 퍼셉트론을 층으로 쌓아 multi-layer-perceptron(다층퍼셉트론) 를 구성하여 비선형 문제를 해결

## 신경망(NeuralNet)
- 처음 입력과 최종 출력 사하이 많은 은닉 층이 존재
- 퍼셉트론과 달리 입력에 편형, 가중치 등이 곱해셔 합산하여 출력되기전 활성화함수(activation function)을 통해 활성화(1)여부를 판단
  - 계단(stp) 함수 : 어느 임계값 이상이면 활성화 시키는 함수, 계산이 간단하지만 그래프가 계단 모양처럼 가파르게 되어 노드들의 데이터를 제대로 출력층으로 반영하지 못함 
  - 시그모이드(sigmoid) 함수 : 그래프가 s 를 닮음, 계산비용이 있지만 s 자 처럼 완만한 곡선으로 입력값들이 제대로 출력층에 반영됨
  - ReLu(Rectified Linear Unit) 함수 : 0 을 넙으려 입력값을 그대로 출력(활성), 계산 비용이 시그모이드보다 적고,의미 있는 입력 데이터도 출력층에 전달 할 수 있어 최근에 많이 쓰임
- 신경만의 입력, 출력을 계산할때는 행렬의 (내적)곱을 사용
  - numpy 의 dot() 사용
- 신경망의 최종 출력 노드들 중 가장 큰 값을 가진 노드를 결과 값이라 판단
- 소프트맥스(softmax) 함수는 최종 출력 노드들 전체 합이 1인 확률을값을 표현하고, 이 값으로 신경망의 입력으로 주어 학습하는데 사용
- 데이터 계산히 배치(batch, 묶음)단위로 처리하여 효율을 높인다
- 신경망을 입력에서 출력을 흘려서(전파해서) 결과(분류, 회귀)를 낸다는 의미로 순전파라고 한다
  - 분류(classification) : 물고기, 사람 등을 분류하는 문제
  - 회귀(regression) : 철수 사진을 보고 몸무게 예측하는 문제

## 신경망 학습(Learning)
- 신경망 학습으로 신경망에서 각 노드들의 최적의 파라미터(편향,가중치)를 찾는다.
- 학습(trainning, 훈련), 시험(test) 데이터로 나누어 실헐
- 신경망 학습이 잘되고 있는지 알기 위한 지표로 손실함수(loss function)을 사용
  - 정답데이터와, 출력데이터 간의 차이를 계산하여 하나의 확률료 나타낸다. 반복되는 학습을 통해 손실함수의 값이 가장 작은 출력데이터를 찾을 수 있다. 다음과 같은 방법이 있다.
    - 평균제곱오차(mean squared error, MSE)
    - 교차엔트로피(cross entropy error CEE)
- 미니 배치 학습
